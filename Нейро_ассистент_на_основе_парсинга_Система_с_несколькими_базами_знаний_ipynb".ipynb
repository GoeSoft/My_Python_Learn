{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 openai numpy tiktoken requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WKIHPqref6C",
        "outputId": "b5be14f5-484a-4fe7-f12e-f641da4ceb9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Загружаем API-ключ из секретов Colab\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Jlx11of9eidC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Список моделей и ссылок\n",
        "documents = {\n",
        "    \"6095B\": \"https://agromester.md/pdf/6095B-New.pdf\",\n",
        "    \"9R\": \"http://agromester.md/pdf/9r.pdf\"\n",
        "}\n",
        "\n",
        "def extract_text_from_pdf(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    pdf_file = BytesIO(response.content)\n",
        "    reader = PdfReader(pdf_file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        extracted = page.extract_text()\n",
        "        if extracted:\n",
        "            text += extracted + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# Загружаем тексты\n",
        "model_texts = {}\n",
        "for model, url in documents.items():\n",
        "    print(f\"Загрузка документа для модели {model}...\")\n",
        "    try:\n",
        "        model_texts[model] = extract_text_from_pdf(url)\n",
        "        print(f\"Успешно загружено: {len(model_texts[model])} символов.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при загрузке {model}: {e}\")\n",
        "        model_texts[model] = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFBTQbBejvy",
        "outputId": "2871900b-30ac-4dff-98d4-b1f434ad8651"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка документа для модели 6095B...\n",
            "Успешно загружено: 29921 символов.\n",
            "Загрузка документа для модели 9R...\n",
            "Успешно загружено: 35132 символов.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def split_into_chunks(text, max_tokens=400):\n",
        "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    tokens = tokenizer.encode(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_tokens):\n",
        "        chunk = tokenizer.decode(tokens[i:i + max_tokens])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "# Храним чанки с меткой модели\n",
        "knowledge_base = {}  # {model: [chunk1, chunk2, ...]}\n",
        "\n",
        "for model, text in model_texts.items():\n",
        "    if text:\n",
        "        knowledge_base[model] = split_into_chunks(text)\n",
        "        print(f\"Модель {model}: разбито на {len(knowledge_base[model])} чанков.\")\n",
        "    else:\n",
        "        knowledge_base[model] = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACDc5Yvses5O",
        "outputId": "0a29a6fa-35a8-40a7-da93-83bef34533e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель 6095B: разбито на 47 чанков.\n",
            "Модель 9R: разбито на 41 чанков.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "\n",
        "# Структура: {model: {\"chunks\": [...], \"embeddings\": np.array}}\n",
        "vector_store = {}\n",
        "\n",
        "for model, chunks in knowledge_base.items():\n",
        "    if not chunks:\n",
        "        vector_store[model] = {\"chunks\": [], \"embeddings\": np.array([])}\n",
        "        continue\n",
        "\n",
        "    print(f\"Создание эмбеддингов для модели {model}...\")\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        emb = get_embedding(chunk)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    vector_store[model] = {\n",
        "        \"chunks\": chunks,\n",
        "        \"embeddings\": np.array(embeddings)\n",
        "    }\n",
        "    print(f\"✅ Эмбеддинги для {model} готовы.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCHFiJqfe1Mj",
        "outputId": "7d0b1922-df61-49a2-8a93-db40805a6e99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создание эмбеддингов для модели 6095B...\n",
            "✅ Эмбеддинги для 6095B готовы.\n",
            "Создание эмбеддингов для модели 9R...\n",
            "✅ Эмбеддинги для 9R готовы.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_model_from_question(question):\n",
        "    question_lower = question.lower()\n",
        "    if \"6095\" in question_lower or \"6095b\" in question_lower:\n",
        "        return \"6095B\"\n",
        "    elif \"9r\" in question_lower:\n",
        "        return \"9R\"\n",
        "    else:\n",
        "        # Если модель не указана — ищем в обеих\n",
        "        return None\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def search_in_model(model, query, top_k=3):\n",
        "    if model not in vector_store or len(vector_store[model][\"embeddings\"]) == 0:\n",
        "        return []\n",
        "\n",
        "    query_emb = get_embedding(query)\n",
        "    embeddings = vector_store[model][\"embeddings\"]\n",
        "    chunks = vector_store[model][\"chunks\"]\n",
        "\n",
        "    scores = [cosine_similarity(query_emb, emb) for emb in embeddings]\n",
        "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "    return [chunks[i] for i in top_indices]"
      ],
      "metadata": {
        "id": "p9rVjzIOe5Qc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_tractor_question(question):\n",
        "    # Шаг 1: Определяем целевую модель\n",
        "    target_model = detect_model_from_question(question)\n",
        "\n",
        "    # Шаг 2: Ищем релевантные чанки\n",
        "    relevant_chunks = []\n",
        "    used_model = None\n",
        "\n",
        "    if target_model:\n",
        "        # Ищем только в указанной модели\n",
        "        relevant_chunks = search_in_model(target_model, question, top_k=3)\n",
        "        used_model = target_model\n",
        "    else:\n",
        "        # Ищем в обеих, выбираем модель с самым релевантным чанком\n",
        "        best_score = -1\n",
        "        best_chunk = \"\"\n",
        "        best_model = None\n",
        "\n",
        "        for model in vector_store:\n",
        "            if not vector_store[model][\"chunks\"]:\n",
        "                continue\n",
        "            query_emb = get_embedding(question)\n",
        "            embeddings = vector_store[model][\"embeddings\"]\n",
        "            scores = [cosine_similarity(query_emb, emb) for emb in embeddings]\n",
        "            max_score = max(scores)\n",
        "            if max_score > best_score:\n",
        "                best_score = max_score\n",
        "                best_model = model\n",
        "                best_idx = np.argmax(scores)\n",
        "                best_chunk = vector_store[model][\"chunks\"][best_idx]\n",
        "\n",
        "        if best_model and best_score > 0.5:  # порог релевантности\n",
        "            relevant_chunks = [best_chunk]\n",
        "            used_model = best_model\n",
        "        else:\n",
        "            return \"К сожалению, по вашему вопросу нет информации в доступных спецификациях тракторов.\"\n",
        "\n",
        "    # Шаг 3: Формируем контекст\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    # Промпт: отвечаем как эксперт, без упоминания документов\n",
        "    system_prompt = (\n",
        "        \"Вы — эксперт по сельскохозяйственной технике и консультант по тракторам. \"\n",
        "        \"Отвечайте на вопросы покупателей чётко, точно и профессионально. \"\n",
        "        \"НИКОГДА не упоминайте документы, PDF, спецификации или источники информации. \"\n",
        "        \"Говорите так, будто вы знаете эти данные по умолчанию. \"\n",
        "        \"Если информации нет — скажите: 'Эта информация не указана в технических данных трактора.'\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"Информация по трактору: {context}\\n\\nВопрос клиента: {question}\\n\\nОтвет:\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "eNVLhew1fAfD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    \"Какая мощность двигателя у трактора 6095B?\",\n",
        "    \"Какой объём топливного бака у 9R?\",\n",
        "    \"Сколько весит трактор 6095B?\",\n",
        "    \"Поддерживает ли 9R навесное оборудование ISOBUS?\",\n",
        "    \"Какая максимальная скорость у трактора с индексом 9R?\",\n",
        "    \"Какой расход топлива у трактора 6095B при полной нагрузке?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"❓ {q}\")\n",
        "    print(f\"✅ {ask_tractor_question(q)}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXVBq1nXfE8s",
        "outputId": "b3bde8af-6699-4462-ca47-eacc3eb8ff88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❓ Какая мощность двигателя у трактора 6095B?\n",
            "✅ Номинальная мощность двигателя трактора 6095B составляет 95 л.с., а максимальная мощность — 96 л.с.\n",
            "--------------------------------------------------------------------------------\n",
            "❓ Какой объём топливного бака у 9R?\n",
            "✅ Объем топливного бака у тракторов серии 9R/RT составляет 1325 литров.\n",
            "--------------------------------------------------------------------------------\n",
            "❓ Сколько весит трактор 6095B?\n",
            "✅ Вес трактора 6095B составляет около 4200 кг без кабины и примерно 4000 кг с кабиной.\n",
            "--------------------------------------------------------------------------------\n",
            "❓ Поддерживает ли 9R навесное оборудование ISOBUS?\n",
            "✅ Да, тракторы серии 9R поддерживают навесное оборудование ISOBUS, что обеспечивает экономию денежных средств и простоту управления орудиями.\n",
            "--------------------------------------------------------------------------------\n",
            "❓ Какая максимальная скорость у трактора с индексом 9R?\n",
            "✅ Максимальная скорость трактора с индексом 9R составляет 40 км/ч.\n",
            "--------------------------------------------------------------------------------\n",
            "❓ Какой расход топлива у трактора 6095B при полной нагрузке?\n",
            "✅ Расход топлива трактора 6095B при полной нагрузке не указан в предоставленной информации.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}