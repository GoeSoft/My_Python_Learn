{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain-core langchain-text-splitters PyDrive2 numpy tiktoken beautifulsoup4 lxml"
      ],
      "metadata": {
        "id": "i9Hgb12RdNSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cea871-9dc9-4299-acc7-61a439763ac8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (0.3.11)\n",
            "Requirement already satisfied: PyDrive2 in /usr/local/lib/python3.12/dist-packages (1.21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.12/dist-packages (from PyDrive2) (2.182.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from PyDrive2) (4.1.3)\n",
            "Requirement already satisfied: cryptography<44 in /usr/local/lib/python3.12/dist-packages (from PyDrive2) (43.0.3)\n",
            "Requirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from PyDrive2) (24.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<44->PyDrive2) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (4.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->PyDrive2) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->PyDrive2) (1.17.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<44->PyDrive2) (2.23)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.12.5->PyDrive2) (5.5.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.12.5->PyDrive2) (3.2.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "3DUUE4nVsfQG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Аутентификация Google Drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Загрузка текста из Google Docs (публичный документ)\n",
        "doc_url = \"https://docs.google.com/document/d/1q4l912Re8zuIfBax4FDS3ZppYmVPzER3Si2wrmznddc\"\n",
        "\n",
        "# Экспорт как HTML\n",
        "export_url = doc_url + \"/export?format=html\"\n",
        "response = requests.get(export_url)\n",
        "response.raise_for_status()\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "text = soup.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "print(f\"✅ Загружено {len(text)} символов из документа.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkmI_bb7sjle",
        "outputId": "e11f0270-9406-4d69-9d9a-88890882448c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Загружено 239809 символов из документа.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "import tiktoken\n",
        "\n",
        "# Функция подсчёта токенов\n",
        "def count_tokens(text):\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    return len(enc.encode(text))\n",
        "\n",
        "# Сначала пробуем разбить по абзацам\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\\n\",\n",
        "    chunk_size=500,        # ~500 символов\n",
        "    chunk_overlap=50,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(text)\n",
        "\n",
        "# Теперь проверим и при необходимости разобьём слишком длинные чанки по токенам\n",
        "max_tokens = 8000  # оставим запас до лимита 8191\n",
        "final_chunks = []\n",
        "\n",
        "for chunk in chunks:\n",
        "    if count_tokens(chunk) <= max_tokens:\n",
        "        final_chunks.append(chunk)\n",
        "    else:\n",
        "        # Резерв: разбиваем по символам с шагом ~6000 символов (примерно <8000 токенов)\n",
        "        # Используем простой слайдинг по символам\n",
        "        start = 0\n",
        "        step = 6000\n",
        "        overlap = 200\n",
        "        while start < len(chunk):\n",
        "            sub_chunk = chunk[start:start + step]\n",
        "            if sub_chunk.strip():\n",
        "                final_chunks.append(sub_chunk)\n",
        "            start += step - overlap\n",
        "\n",
        "chunks = final_chunks\n",
        "\n",
        "# Убедимся, что все чанки в пределах лимита\n",
        "for i, c in enumerate(chunks):\n",
        "    tok = count_tokens(c)\n",
        "    if tok > 8191:\n",
        "        print(f\"⚠️ Чанк {i} всё ещё слишком длинный: {tok} токенов\")\n",
        "\n",
        "print(f\"📄 Разбито на {len(chunks)} чанков. Макс. длина чанка: {max(count_tokens(c) for c in chunks)} токенов.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EbTspKGtOfT",
        "outputId": "791ba70a-6d31-4f81-8ec7-b47d991ae6db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Разбито на 42 чанков. Макс. длина чанка: 3021 токенов.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "\n",
        "# Генерация эмбеддингов\n",
        "print(\"Генерация эмбеддингов...\")\n",
        "embeddings = []\n",
        "for i, chunk in enumerate(chunks):\n",
        "    emb = get_embedding(chunk)\n",
        "    embeddings.append(emb)\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f\"Обработано {i + 1} чанков...\")\n",
        "\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Сохраняем как pickle: (chunks, embeddings)\n",
        "vector_db = {\"chunks\": chunks, \"embeddings\": embeddings}\n",
        "\n",
        "# Сохраняем локально\n",
        "with open(\"vector_db.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vector_db, f)\n",
        "\n",
        "# Загружаем на Google Drive\n",
        "uploaded = drive.CreateFile({'title': 'vector_db.pkl'})\n",
        "uploaded.SetContentFile('vector_db.pkl')\n",
        "uploaded.Upload()\n",
        "print(f\"💾 Векторная база сохранена на Google Drive с ID: {uploaded.get('id')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgxam9fPtT6C",
        "outputId": "3d6bd704-e04b-41ab-a666-acd57ad8af3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация эмбеддингов...\n",
            "Обработано 20 чанков...\n",
            "Обработано 40 чанков...\n",
            "💾 Векторная база сохранена на Google Drive с ID: 1CHkCJ8Hp1_C_M3C0_cSzD9bNvel19Oc0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачиваем файл с Google Drive (по названию)\n",
        "file_list = drive.ListFile({'q': \"'root' in parents and title='vector_db.pkl'\"}).GetList()\n",
        "if not file_list:\n",
        "    raise FileNotFoundError(\"Файл vector_db.pkl не найден на Google Drive\")\n",
        "\n",
        "file_id = file_list[0]['id']\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('vector_db_downloaded.pkl')\n",
        "\n",
        "# Загружаем\n",
        "with open(\"vector_db_downloaded.pkl\", \"rb\") as f:\n",
        "    loaded_db = pickle.load(f)\n",
        "\n",
        "chunks_loaded = loaded_db[\"chunks\"]\n",
        "embeddings_loaded = loaded_db[\"embeddings\"]\n",
        "\n",
        "print(f\"✅ Загружено {len(chunks_loaded)} чанков из Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4-2XawPt9yP",
        "outputId": "7eae9c7a-7161-4136-ef29-8da3b7772e9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Загружено 42 чанков из Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def ask_safety_question(question, top_k=3):\n",
        "    # Получаем эмбеддинг вопроса\n",
        "    query_emb = get_embedding(question)\n",
        "\n",
        "    # Ищем наиболее релевантные чанки\n",
        "    scores = [cosine_similarity(query_emb, emb) for emb in embeddings_loaded]\n",
        "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "    top_chunks = [chunks_loaded[i] for i in top_indices]\n",
        "\n",
        "    context = \"\\n\\n\".join(top_chunks)\n",
        "\n",
        "    # Генерация ответа через OpenAI (без LangChain!)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"Вы — эксперт по промышленной безопасности. \"\n",
        "                    \"Отвечайте на вопросы строго на основе предоставленной информации. \"\n",
        "                    \"Если информации нет, скажите: 'В документе по безопасности эта информация не содержится.'\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Контекст:\\n{context}\\n\\nВопрос: {question}\\n\\nОтвет:\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "JiwoW5RouDAe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Какие требования предъявляются к обучению персонала на опасных производственных объектах?\"\n",
        "\n",
        "answer = ask_safety_question(question)\n",
        "print(\"❓ Вопрос:\", question)\n",
        "print(\"\\n✅ Ответ:\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uMsJh30uLvW",
        "outputId": "e1c916ef-8342-4535-fb32-6a711991cab8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❓ Вопрос: Какие требования предъявляются к обучению персонала на опасных производственных объектах?\n",
            "\n",
            "✅ Ответ:\n",
            "В документе по безопасности содержится информация о требованиях к обучению персонала на опасных производственных объектах. Согласно представленному контексту, эксплуатирующая организация обязана устанавливать порядок контроля обучения и периодической проверки знаний персонала, работающего с ограничителями, указателями и регистраторами, а также документально подтверждать его соблюдение с учетом требований руководства (инструкции) по эксплуатации. Также организация должна организовывать считывание данных с регистратора параметров работы ПС, обработку этих данных, выявление нарушений правил эксплуатации ПС, а при отсутствии указаний о сроках считывания данных проводить такие операции не реже одного раза в шесть месяцев.\n"
          ]
        }
      ]
    }
  ]
}